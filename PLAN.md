# RAGRouter v2 — Implementation Plan

> This document is the source of truth for all design decisions.
> Reference this file when implementing to avoid drift.

---

## Overview

RAGRouter routes user questions to either:
- **Direct path**: LLM answers without retrieval (fast)
- **RAG path**: Retrieve documents first, then LLM answers with context (accurate)

The goal is **real latency savings**: we decide the route BEFORE calling retrieval.

---

## Core Design Decisions

### 1. Routing Logic

```
Question arrives
       ↓
┌──────────────────────┐
│ Keyword check        │  ← If domain keywords found → RAG
│ (configurable list)  │
└──────────┬───────────┘
           │
     no match
           ↓
┌──────────────────────┐
│ Classifier           │  ← ML model predicts route
│ (query features only)│
└──────────┬───────────┘
           │
    ┌──────┴──────┐
    ↓             ↓
  "rag"       "direct"
    ↓             ↓
 retrieve()    generate()
 generate()    (no retrieval)
```

**Key rule**: No retrieval call until AFTER we decide "rag".

### 2. Training Pipeline

Labels are generated by testing the LLM:

```
For each question in dataset:
    1. Ask LLM the question (no context)
    2. Compare LLM answer to real answer
    3. If correct → label "direct"
       If wrong  → label "rag"
    4. Extract query-only features
    5. Store (features, label)

Train classifier on (features, labels)
Save to models/router.joblib
```

### 3. Query-Only Features (used at inference)

| Feature | Description |
|---------|-------------|
| `len_words` | Word count |
| `len_chars` | Character count |
| `has_number` | Contains digits (0/1) |
| `wh_type` | Question word (what/who/where/when/why/how/other) → one-hot |
| `num_entities` | Count of capitalized words |
| `domain_vocab_score` | % of tokens found in corpus vocabulary |
| `avg_word_length` | Average word length |
| `has_question_mark` | Ends with ? (0/1) |

**None of these require retrieval.**

### 4. Fallback Behavior

- If classifier model doesn't exist → default to "rag" (safe)
- If keywords match → always "rag" (skip classifier)

---

## Technical Decisions

### Embedding Model: e5-small

- Model: `intfloat/e5-small`
- **Must use prefixes**:
  - Documents: `"passage: {text}"`
  - Queries: `"query: {text}"`

### Chunking

- Window size: L = 512 tokens
- Stride: S = 128 tokens (overlap)
- Tokenizer: tiktoken `cl100k_base`

### Vector Database: ChromaDB

- Connection: HTTP client to `localhost:8000`
- Collection: `kb_main`
- Metric: cosine similarity

### LLM: Ollama

- Model: `qwen2.5:0.5b-instruct`
- Host: `http://localhost:11434`
- Prompts: **English only**

### Dataset

- Source: [sentence-transformers/natural-questions](https://huggingface.co/datasets/sentence-transformers/natural-questions)
- Size: ~100k question-answer pairs
- Usage: Generate labels by testing LLM accuracy

---

## File Structure

```
src/
├── config.py       # All settings, paths, constants
├── router.py       # Keyword check + classifier (train + predict)
├── retriever.py    # Embedding + ChromaDB + ingest + chunking
├── generator.py    # LLM calls (direct + RAG prompts)
└── api.py          # FastAPI /ask endpoint

scripts/
├── ingest.py       # CLI: python scripts/ingest.py --corpus data/corpus
├── label.py        # CLI: python scripts/label.py --dataset nq --output data/labels.jsonl
└── train.py        # CLI: python scripts/train.py --labels data/labels.jsonl

models/
├── router.joblib   # Trained classifier
└── tfidf.joblib    # Corpus vocabulary vectorizer

data/
├── corpus/         # Documents to ingest
├── keywords.txt    # Domain keywords (one per line)
└── labels.jsonl    # Training labels

ui/
└── app.py          # Streamlit demo (unchanged)
```

---

## API Response Format

```json
POST /ask
{
  "question": "What is RMSE?"
}

Response:
{
  "route": "direct",
  "answer": "RMSE (Root Mean Square Error) is...",
  "passages": [],
  "timing_ms": 450
}
```

For RAG route, `passages` contains:
```json
"passages": [
  {"text": "...", "source": "file.txt", "score": 0.82}
]
```

---

## Implementation Order

1. `config.py` — All constants in one place
2. `retriever.py` — Embedding, chunking, ChromaDB
3. `generator.py` — LLM direct + RAG generation
4. `router.py` — Keywords + classifier
5. `api.py` — FastAPI orchestration
6. `scripts/` — CLI tools for ingest, label, train
7. Delete old files, update README

---

## What We're NOT Doing (v2 scope)

- No re-ranking (MMR) — keep it simple
- No GPU support — CPU only
- No multiple LLM backends — just Ollama
- No evaluation dashboard — later
- No fancy error handling — just raise exceptions

---

## Reminders

- **E5 prefixes**: Always use "query: " and "passage: "
- **English only**: All prompts in English
- **No retrieval in router**: Classifier uses query features only
- **Keywords file**: `data/keywords.txt`, one keyword per line
- **Config is truth**: All paths/settings come from config.py
